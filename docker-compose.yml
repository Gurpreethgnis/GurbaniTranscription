services:
  transcription-app:
    build: .
    container_name: katha-transcription
    ports:
      - "5000:5000"
    volumes:
      # Persist uploads, outputs, and logs
      - ./uploads:/app/uploads
      - ./outputs:/app/outputs
      - ./logs:/app/logs
      # Cache Whisper models (optional, but speeds up restarts)
      - whisper-cache:/root/.cache/whisper
    environment:
      - FLASK_ENV=production
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    # Enable GPU access
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
          cpus: '2'
          memory: 4G
        limits:
          cpus: '4'
          memory: 8G

volumes:
  whisper-cache:
    driver: local
